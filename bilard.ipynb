{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Śledzenie gry w bilard**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autorzy: Joanna Cicha, Przemysław Łabuń, Maciej Mak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Przygotowanie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from loky import get_reusable_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads frames from the video, which will be used as the dataset for tracking and analysis.\n",
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "        i += 1\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# Loads templates that are necessary for object detection in video frames.\n",
    "def load_templates(template_folder, suffix):\n",
    "    templates = []\n",
    "    for filename in os.listdir(template_folder):\n",
    "        if filename.endswith(suffix):\n",
    "            path = os.path.join(template_folder, filename)\n",
    "            template = cv2.imread(path, 0)\n",
    "            templates.append(template)\n",
    "    return templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Wykorzystane techniki**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. Template Matching** <br>\n",
    "<br>\n",
    "Technika do wykrywania określonych obiektów (takich jak kule i łuzy) w ramkach wideo. Polega na użyciu predefiniowanych szablonów – małych obrazów obiektów zainteresowania – i przesuwaniu tych szablonów po docelowej ramce, aby znaleźć dopasowania na podstawie metryki podobieństwa. <br><br>\n",
    "\n",
    "**2.2. Transformacje Geometryczne i Rysowanie** <br><br>\n",
    "Do wizualnego podkreślenia wykrytych obiektów i zdarzeń w wideo używane są funkcje transformacji geometrycznych i rysowania. <br><br>\n",
    "\n",
    "**2.3. Filtrowanie Bliskich Punktów** <br><br>\n",
    "Aby unikać wielokrotnych wykryć tego samego obiektu, punkty znajdujące się zbyt blisko siebie są filtrowane.<br><br>\n",
    "\n",
    "**2.4. Przetwarzanie Równoległe** <br><br>\n",
    "Aby zwiększyć wydajność przetwarzania wielu klatek wideo, szczególnie dla filmów o wysokiej rozdzielczości, używane jest przetwarzanie równoległe.<br><br>\n",
    "\n",
    "**2.5. Odczytywanie i Zapisywanie Wideo** <br><br>\n",
    "Polega na ekstrakcji klatek z pliku wideo, a następnie kompilacji przetworzonych klatek z powrotem na wideo. <br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters out points that are too close to each other based on a given threshold.\n",
    "def filter_close_points(points, threshold):\n",
    "    keep_points = []\n",
    "    for point in points:\n",
    "        if keep_points:\n",
    "            distances = np.linalg.norm(np.array(keep_points)[:, :2] - point[:2], axis=1)\n",
    "            if np.all(distances > threshold):\n",
    "                keep_points.append(point)\n",
    "        else:\n",
    "            keep_points.append(point)\n",
    "    return np.array(keep_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangles(frame, matched_points):\n",
    "    for (x, y, w, h) in matched_points:\n",
    "        cv2.rectangle(frame, (x - w // 2, y - h // 2), (x + w // 2, y + h // 2), (255, 0, 0), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches given templates with the frame content above a certain threshold and returns the center points of matched areas.\n",
    "def match_templates(frame, templates, threshold=0.8, n=1):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    matched_points = []\n",
    "    for template in templates:\n",
    "        w, h = template.shape[::-1]\n",
    "        res = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "        loc = np.where(res >= threshold)\n",
    "        for pt in zip(*loc[::-1]):  # Reverse tuple to get (x, y) coordinates\n",
    "            center_point = [pt[0] + w // 2, pt[1] + h // 2, w, h]\n",
    "            matched_points.append(center_point)\n",
    "    matched_points = np.array(matched_points)\n",
    "    matched_points = filter_close_points(matched_points, 50).tolist()\n",
    "    return matched_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifies initial positions of pool sockets by matching templates from the first frame.\n",
    "def get_initial_socket_positions(frame, pocket_template_folder, suffix='.png'):\n",
    "    pocket_templates = load_templates(pocket_template_folder, suffix)\n",
    "    pocket_positions = match_templates(frame, pocket_templates, 0.85)\n",
    "    return pocket_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects collisions between the white ball and other balls.\n",
    "def detect_collision(white_ball_position, other_balls_positions, ball_radius):\n",
    "    collisions = []\n",
    "    for index, pos in enumerate(other_balls_positions):\n",
    "        distance = np.linalg.norm(np.array(white_ball_position[:2]) - np.array(pos[:2]))\n",
    "        print(f\"Distance between balls {index} and white ball: {distance}\")\n",
    "        total_radius = 2 * ball_radius \n",
    "        if distance <= total_radius:\n",
    "            collisions.append(index)\n",
    "    return collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts socket positions from the first frame of a video sequence.\n",
    "def get_socket_positions_from_first_frame(frames, pocket_template_folder):\n",
    "    if not frames:\n",
    "        return None, [] \n",
    "    first_frame = frames[0]\n",
    "    pocket_templates = load_templates(pocket_template_folder, '.png')\n",
    "    pocket_positions = match_templates(first_frame, pocket_templates, 0.75)\n",
    "    return first_frame, pocket_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates positions for the middle top and bottom sockets based on the leftmost and rightmost detected positions.\n",
    "def calculate_middle_sockets(pocket_positions):\n",
    "    leftmost, rightmost = pocket_positions[0], pocket_positions[-1]\n",
    "    middle_top = ((leftmost[0] + rightmost[0]) // 2, min(leftmost[1], rightmost[1]))\n",
    "    middle_bottom = ((leftmost[0] + rightmost[0]) // 2, max(leftmost[1], rightmost[1]))\n",
    "    return middle_top, middle_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process each frame, applying template matching, drawing results, and detecting objects' interactions.\n",
    "def process_frame(frame_args):\n",
    "    frame, i, ball_template_folder, socket_positions = frame_args\n",
    "    \n",
    "    ball_templates = load_templates(ball_template_folder, '.png')\n",
    "    \n",
    "    ball_positions = match_templates(frame, ball_templates, 0.9)\n",
    "\n",
    "    frame_with_balls = draw_rectangles(frame, ball_positions)\n",
    "    frame_with_pockets = draw_rectangles(frame_with_balls, socket_positions)\n",
    "\n",
    "    if len(socket_positions) >= 2:\n",
    "        middle_top, middle_bottom = calculate_middle_sockets(socket_positions)\n",
    "        cv2.circle(frame_with_pockets, middle_top, 10, (0, 255, 255), -1)\n",
    "        cv2.circle(frame_with_pockets, middle_bottom, 10, (0, 255, 255), -1)\n",
    "\n",
    "    message = None\n",
    "    for ball_pos in ball_positions:\n",
    "        for pocket_pos in socket_positions:\n",
    "            x, y, w, h = pocket_pos\n",
    "            pocket_center = (x, y)\n",
    "            distance = np.linalg.norm(np.array(ball_pos[:2]) - np.array(pocket_center))\n",
    "            if distance < 100:\n",
    "                message = f\"Ball in the socket at position: {ball_pos[:2]} in frame {i}\"\n",
    "                cv2.putText(frame_with_pockets, message, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                break \n",
    "        if message:\n",
    "            break \n",
    "    img = frame_with_balls\n",
    "    cv2.imwrite(f\"results/frame_{i}.jpg\", img)\n",
    "\n",
    "    return ball_positions\n",
    "\n",
    "ball_radius = 11\n",
    "ball_template_folder = 'template'\n",
    "pocket_template_folder = 'sockets'\n",
    "video_path = 'bilard.mp4'\n",
    "frames = read_video(video_path)\n",
    "initial_frame, initial_socket_positions = get_socket_positions_from_first_frame(frames, pocket_template_folder)\n",
    "\n",
    "if initial_frame is not None:\n",
    "    executor = get_reusable_executor(max_workers=16, timeout=2)\n",
    "    frame_args = [(frame, i, ball_template_folder, initial_socket_positions) for i, frame in enumerate(frames)]\n",
    "    results = executor.map(process_frame, frame_args)\n",
    "    frames_ball_positions = list(results)\n",
    "else:\n",
    "    print(\"No frames available to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines processed frames into a video file.\n",
    "def create_video_from_images(image_folder, output_video, frame_rate=30):\n",
    "    image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
    "    image_files = sorted(image_files, key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n",
    "\n",
    "    first_image = cv2.imread(image_files[0])\n",
    "    height, width, layers = first_image.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, frame_rate, (width, height))\n",
    "\n",
    "    for filename in image_files:\n",
    "        img = cv2.imread(filename)\n",
    "        out.write(img)\n",
    "\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "create_video_from_images('results', 'movie.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
